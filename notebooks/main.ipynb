{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":29653,"databundleVersionId":2420395,"sourceType":"competition"}],"dockerImageVersionId":30197,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Importar libreria**","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport pydicom as dicom\nimport cv2\nimport ast\n\nimport glob\nimport re\nimport math\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras import applications ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-17T15:11:05.748146Z","iopub.execute_input":"2022-06-17T15:11:05.748554Z","iopub.status.idle":"2022-06-17T15:11:13.991178Z","shell.execute_reply.started":"2022-06-17T15:11:05.74848Z","shell.execute_reply":"2022-06-17T15:11:13.990216Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Enlace de la base de datos\npath = '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/'\nos.listdir(path)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:13.994712Z","iopub.execute_input":"2022-06-17T15:11:13.996151Z","iopub.status.idle":"2022-06-17T15:11:14.007481Z","shell.execute_reply.started":"2022-06-17T15:11:13.996109Z","shell.execute_reply":"2022-06-17T15:11:14.006525Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Cargar base de datos**","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(path+'train_labels.csv')\nsamp_subm  = pd.read_csv(path+'sample_submission.csv')\n\nprint(train_data.head(7)),print(samp_subm.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.009239Z","iopub.execute_input":"2022-06-17T15:11:14.009829Z","iopub.status.idle":"2022-06-17T15:11:14.045218Z","shell.execute_reply.started":"2022-06-17T15:11:14.009788Z","shell.execute_reply":"2022-06-17T15:11:14.044379Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **2 Compresión de los datos** \nMetodologia Crisp-DM","metadata":{}},{"cell_type":"code","source":"#Imprimir tamaño de carpetas por TRAIN Y TEST\nprint('Samples train:', len(train_data))\nprint('Samples test:', len(samp_subm))","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.047576Z","iopub.execute_input":"2022-06-17T15:11:14.048237Z","iopub.status.idle":"2022-06-17T15:11:14.053867Z","shell.execute_reply.started":"2022-06-17T15:11:14.048199Z","shell.execute_reply":"2022-06-17T15:11:14.052719Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.head(7)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.055792Z","iopub.execute_input":"2022-06-17T15:11:14.056455Z","iopub.status.idle":"2022-06-17T15:11:14.069477Z","shell.execute_reply.started":"2022-06-17T15:11:14.056412Z","shell.execute_reply":"2022-06-17T15:11:14.06851Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## analisis de datos faltantes\nprint(pd.isnull(train_data).sum()) \nprint('___________')\nprint(pd.isnull(samp_subm ).sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.070983Z","iopub.execute_input":"2022-06-17T15:11:14.071358Z","iopub.status.idle":"2022-06-17T15:11:14.080736Z","shell.execute_reply.started":"2022-06-17T15:11:14.071322Z","shell.execute_reply":"2022-06-17T15:11:14.079715Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data[\"MGMT_value\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.082457Z","iopub.execute_input":"2022-06-17T15:11:14.083283Z","iopub.status.idle":"2022-06-17T15:11:14.095571Z","shell.execute_reply.started":"2022-06-17T15:11:14.083232Z","shell.execute_reply":"2022-06-17T15:11:14.094701Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"to_exclude = [109, 123, 709]\n\ntrain_data = train_data[~train_data['BraTS21ID'].isin(to_exclude)]\nnum_samples = train_data.shape[0]\nnum_positives = np.sum(train_data['MGMT_value'] == 1)\nnum_negatives = np.sum(train_data['MGMT_value'] == 0)\n\n\ntrain_data[\"MGMT_value\"].value_counts().head(2).plot(kind = 'pie',autopct='%1.1f%%', figsize=(8, 8)).legend()\n\n\ntrain_data.hist(column=\"MGMT_value\")","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.097106Z","iopub.execute_input":"2022-06-17T15:11:14.097525Z","iopub.status.idle":"2022-06-17T15:11:14.481173Z","shell.execute_reply.started":"2022-06-17T15:11:14.097488Z","shell.execute_reply":"2022-06-17T15:11:14.480441Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"samp_subm.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.482683Z","iopub.execute_input":"2022-06-17T15:11:14.483268Z","iopub.status.idle":"2022-06-17T15:11:14.493472Z","shell.execute_reply.started":"2022-06-17T15:11:14.483206Z","shell.execute_reply":"2022-06-17T15:11:14.492704Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#analizar una carpeta 100--->00150\nfolder = str(train_data.loc[100, 'BraTS21ID']).zfill(5)\nfolder","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.498022Z","iopub.execute_input":"2022-06-17T15:11:14.498563Z","iopub.status.idle":"2022-06-17T15:11:14.505216Z","shell.execute_reply.started":"2022-06-17T15:11:14.49853Z","shell.execute_reply":"2022-06-17T15:11:14.504224Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## CONTENIDO DE LAS CARPETAS\nos.listdir(path+'train/'+folder)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.506838Z","iopub.execute_input":"2022-06-17T15:11:14.507442Z","iopub.status.idle":"2022-06-17T15:11:14.52013Z","shell.execute_reply.started":"2022-06-17T15:11:14.507399Z","shell.execute_reply":"2022-06-17T15:11:14.519395Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Explicacion de las tecnicas T2w, T1wCE, T1w, FLAIR\n![](https://i.postimg.cc/3NS5z6RB/image.png)\n","metadata":{}},{"cell_type":"code","source":"#numero de imagenes por capeta\nprint('Number of FLAIR images:', len(os.listdir(path+'train/'+folder+'/'+'FLAIR')))\nprint('Number of T1w images:',   len(os.listdir(path+'train/'+folder+'/'+'T1w')))\nprint('Number of T1wCE images:', len(os.listdir(path+'train/'+folder+'/'+'T1wCE')))\nprint('Number of T2w images:',   len(os.listdir(path+'train/'+folder+'/'+'T2w')))","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.521117Z","iopub.execute_input":"2022-06-17T15:11:14.521381Z","iopub.status.idle":"2022-06-17T15:11:14.556065Z","shell.execute_reply.started":"2022-06-17T15:11:14.521357Z","shell.execute_reply":"2022-06-17T15:11:14.555232Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Cargar imagenes\npath_file = ''.join([path, 'train/', folder, '/', 'FLAIR/'])\nimage = os.listdir(path_file)[0]\ndata_file = dicom.dcmread(path_file+image)\nimg = data_file.pixel_array","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.557268Z","iopub.execute_input":"2022-06-17T15:11:14.557598Z","iopub.status.idle":"2022-06-17T15:11:14.573585Z","shell.execute_reply.started":"2022-06-17T15:11:14.557566Z","shell.execute_reply":"2022-06-17T15:11:14.572906Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Forma de la imagen (Tamaño)\nprint('Image shape:', img.shape)\n###print(train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.574745Z","iopub.execute_input":"2022-06-17T15:11:14.575162Z","iopub.status.idle":"2022-06-17T15:11:14.579813Z","shell.execute_reply.started":"2022-06-17T15:11:14.575109Z","shell.execute_reply":"2022-06-17T15:11:14.578954Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## IMAGENES FLAIR\ndef plot_examples(row = 0, cat = 'FLAIR'): \n    folder = str(train_data.loc[row, 'BraTS21ID']).zfill(5)\n    path_file = ''.join([path, 'train/', folder, '/', cat, '/'])\n    images = os.listdir(path_file)\n    \n    fig, axs = plt.subplots(1, 5, figsize=(30, 30))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    \n    for num in range(5):\n        data_file = dicom.dcmread(path_file+images[num])\n        img = data_file.pixel_array\n        axs[num].imshow(img, cmap='gray')\n        axs[num].set_title(cat+' '+images[num])\n        axs[num].set_xticklabels([])\n        axs[num].set_yticklabels([])\n        \nrow = 0\nplot_examples(row = row, cat = 'FLAIR')","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:14.581237Z","iopub.execute_input":"2022-06-17T15:11:14.582019Z","iopub.status.idle":"2022-06-17T15:11:15.311805Z","shell.execute_reply.started":"2022-06-17T15:11:14.581982Z","shell.execute_reply":"2022-06-17T15:11:15.31103Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"##IMAGENES T1W\nplot_examples(row = row, cat = 'T1w')","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:15.312734Z","iopub.execute_input":"2022-06-17T15:11:15.313055Z","iopub.status.idle":"2022-06-17T15:11:15.928061Z","shell.execute_reply.started":"2022-06-17T15:11:15.313022Z","shell.execute_reply":"2022-06-17T15:11:15.926572Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## IMAGENES T1CE\nplot_examples(row = row, cat = 'T1wCE')","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:15.929485Z","iopub.execute_input":"2022-06-17T15:11:15.930083Z","iopub.status.idle":"2022-06-17T15:11:16.757484Z","shell.execute_reply.started":"2022-06-17T15:11:15.930045Z","shell.execute_reply":"2022-06-17T15:11:16.756713Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"##IMAGENES T2W\nplot_examples(row = row, cat = 'T2w')","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:16.758779Z","iopub.execute_input":"2022-06-17T15:11:16.759297Z","iopub.status.idle":"2022-06-17T15:11:17.489451Z","shell.execute_reply.started":"2022-06-17T15:11:16.759251Z","shell.execute_reply":"2022-06-17T15:11:17.488707Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"![](https://i.pinimg.com/originals/15/7f/99/157f9957ecd64da6b079ff5189dbf3ff.gif)","metadata":{}},{"cell_type":"markdown","source":"# **3 Preparacion de los datos**\n\nPREPROCESAMIENTO DE IMAGEN\n\nPara cada paciente, realizaremos un preprocesado de las imágenes aplicando estas diferentes modificaciones:\n* Cargue una secuencia ordenada de 64 resonancias magnéticas\n* Recortar imágenes para reducir los bordes negros\n* Cambiar el tamaño de la imagen para reducir los 0 de la matriz para el modelo previo al entrenamiento\n* Aplicar filtro de eliminación de ruido\n* Convierta cada imagen en una matriz 3D\n","metadata":{}},{"cell_type":"code","source":"#Datos\ndata_directory = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/'\ntrain_df = pd.read_csv(data_directory+\"train_labels.csv\")\ntrain_df['BraTS21ID5'] = [format(x, '05d') for x in train_df.BraTS21ID]\ntrain_df.head(3)\ntest = pd.read_csv(\n    data_directory+'sample_submission.csv')\n\ntest['BraTS21ID5'] = [format(x, '05d') for x in test.BraTS21ID]","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:17.490762Z","iopub.execute_input":"2022-06-17T15:11:17.491275Z","iopub.status.idle":"2022-06-17T15:11:17.504576Z","shell.execute_reply.started":"2022-06-17T15:11:17.491227Z","shell.execute_reply":"2022-06-17T15:11:17.503813Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_SIZE = 240\nSCALE = .8\nNUM_IMAGES = 64\nMRI_TYPE = \"FLAIR\"","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:17.505932Z","iopub.execute_input":"2022-06-17T15:11:17.506285Z","iopub.status.idle":"2022-06-17T15:11:17.51183Z","shell.execute_reply.started":"2022-06-17T15:11:17.50624Z","shell.execute_reply":"2022-06-17T15:11:17.510722Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#CARGAR IMAEGN dicom, RECORTAR Y APLICAR FILTRO DENOISING \ndef load_dicom_image(\n    path,\n    img_size=IMAGE_SIZE,\n    scale=SCALE):\n# Cargar imagen \n    img = dicom.read_file(path).pixel_array\n    # recorte imagen\n    center_x, center_y = img.shape[1] / 2, img.shape[0] / 2\n    width_scaled, height_scaled = img.shape[1] * scale, img.shape[0] * scale\n    left_x, right_x = center_x - width_scaled / 2, center_x + width_scaled / 2\n    top_y, bottom_y = center_y - height_scaled / 2, center_y + height_scaled / 2\n    img = img[int(top_y):int(bottom_y), int(left_x):int(right_x)]\n\n    img = cv2.resize(img, (img_size, img_size))\n    #cv2.fastNlMeansDenoisingMulti() \n    \n    # Convertir en matriz 3D\n    img = np.repeat(img[..., np.newaxis], 3, -1)\n    \n    return img","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:17.51322Z","iopub.execute_input":"2022-06-17T15:11:17.51375Z","iopub.status.idle":"2022-06-17T15:11:17.523906Z","shell.execute_reply.started":"2022-06-17T15:11:17.513697Z","shell.execute_reply":"2022-06-17T15:11:17.523074Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"![](http://people.tuebingen.mpg.de/burger/neural_denoising/images/denoising.png)","metadata":{}},{"cell_type":"markdown","source":"Podemos verificar el resultado de estos diferentes pasos de preprocesamiento","metadata":{}},{"cell_type":"code","source":"sample_img = dicom.read_file(\n    data_directory+\"train/00046/FLAIR/Image-115.dcm\").pixel_array\npreproc_img = load_dicom_image(data_directory+\"train/00046/FLAIR/Image-115.dcm\")\n\n\nfig = plt.figure(figsize=(12,8))\nax1 = plt.subplot(1,2,1)\nax1.imshow(sample_img, cmap=\"gray\")\nax1.set_title(f\"Original image shape = {sample_img.shape}\")\nax2 = plt.subplot(1,2,2)\nax2.imshow(preproc_img[:,:,0], cmap=\"gray\")\nax2.set_title(f\"Preproc image shape = {preproc_img.shape}\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:17.525078Z","iopub.execute_input":"2022-06-17T15:11:17.525409Z","iopub.status.idle":"2022-06-17T15:11:17.881219Z","shell.execute_reply.started":"2022-06-17T15:11:17.525371Z","shell.execute_reply":"2022-06-17T15:11:17.8805Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Selecionamos imagen central de cada carpeta y selecionamos igual numero de imaganes a cada lado (Evitar imagenes negras)","metadata":{}},{"cell_type":"code","source":"def load_dicom_images_3d(\n    scan_id, \n    num_imgs=NUM_IMAGES, \n    img_size=IMAGE_SIZE, \n    mri_type=MRI_TYPE, \n    split=\"train\"):\n    \n    files = sorted(glob.glob(f\"{data_directory}{split}/{scan_id}/{mri_type}/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\n    middle = len(files)//2\n    num_imgs2 = num_imgs//2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f) for f in files[p1:p2]]) \n    if img3d.shape[0] < num_imgs:\n        n_zero = np.zeros((num_imgs - img3d.shape[0], img_size, img_size, 3))\n        img3d = np.concatenate((img3d,  n_zero), axis = 0)\n            \n    return img3d","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:17.882495Z","iopub.execute_input":"2022-06-17T15:11:17.883237Z","iopub.status.idle":"2022-06-17T15:11:17.892011Z","shell.execute_reply.started":"2022-06-17T15:11:17.8832Z","shell.execute_reply":"2022-06-17T15:11:17.891299Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Prueba de carga de una secuencia de imágenes preprocesadas para un paciente:","metadata":{}},{"cell_type":"code","source":"sample_seq = load_dicom_images_3d(\"00046\")\nprint(\"Shape of the sequence is:\", sample_seq.shape)\nprint(\"Dimension of the 15th image in sequence is:\", sample_seq[15].shape)\nfig = plt.figure(figsize=(5,5))\nplt.imshow(np.squeeze(sample_seq[15][:,:,0]), cmap=\"gray\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:17.893354Z","iopub.execute_input":"2022-06-17T15:11:17.893771Z","iopub.status.idle":"2022-06-17T15:11:18.916448Z","shell.execute_reply.started":"2022-06-17T15:11:17.893723Z","shell.execute_reply":"2022-06-17T15:11:18.915775Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **4 Modelado**","metadata":{}},{"cell_type":"markdown","source":"CARGAR MODELO RESNET50 PREENTRENADO\nPara realizar el Transfer Learning sobre cada imagen de la secuencia, cargaremos un modelo preentrenado gracias a Keras.applications con los pesos preentrenados en ImageNet.\n\n![](https://i0.wp.com/www.datasmarts.net/wp-content/uploads/2019/10/1_IlzW43-NtJrwqtt5Xy3ISA.jpeg?fit=750%2C300&ssl=1)","metadata":{}},{"cell_type":"code","source":"base_resnet = keras.applications.ResNet50(\n    weights=None,\n    #weights=\"imagenet\",\n    pooling='avg',\n    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n    include_top=False)\n\n\"\"\"\nbase_resnet.save_weights(\n'base_resnet_imagenet.h5')\n\n\"\"\"\n#base_resnet.load_weights(\n# '../input/resnet-imagenet-weights/base_resnet_imagenet.h5')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:18.920043Z","iopub.execute_input":"2022-06-17T15:11:18.922305Z","iopub.status.idle":"2022-06-17T15:11:24.814471Z","shell.execute_reply.started":"2022-06-17T15:11:18.922257Z","shell.execute_reply":"2022-06-17T15:11:24.813589Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"También vamos a corregir todas las capas del modelo para que no se vuelvan a entrenar para la detección de características. La capa de clasificación tampoco se carga (include_top = False).","metadata":{}},{"cell_type":"code","source":"base_resnet.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:24.815698Z","iopub.execute_input":"2022-06-17T15:11:24.816067Z","iopub.status.idle":"2022-06-17T15:11:24.826723Z","shell.execute_reply.started":"2022-06-17T15:11:24.816031Z","shell.execute_reply":"2022-06-17T15:11:24.825631Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"CREAR UNA MATRIZ DE VECTORES EN BASE A RESNET50 PARA CADA SECUENCIA DE PACIENTE\nPara esta parte de Transfer Learning, no entrenaremos el modelo ResNet50 sino que solo realizaremos la predicción para cada imagen de la secuencia de cada paciente.\nObtendremos así, para cada imagen, una matriz de pesos del modelo que integraremos en una lista para recrear la secuencia del paciente.\nFinalmente, vamos a crear una matriz global que agrupará las secuencias de x matrices ResNet50.predict para todos los pacientes.\n\nVeamos el pseudocódigo:\n\n```Python\n`# Transfert Learning\nlistMatrix = []\nfor person in persons:\n    listVectors = []\n    for image in person.images:\n        img = preprocess(image)\n        vector = baseModel.predict(img)\n        listVectors.append(vector)\n\n    PatientMatrix = np.stack(listVectors)\n    listMatrix.append(PatientMatrix)","metadata":{}},{"cell_type":"code","source":"train = train_df[['BraTS21ID5','MGMT_value']]\nX_train = train['BraTS21ID5'].values\ny_train = train['MGMT_value'].values","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:24.828303Z","iopub.execute_input":"2022-06-17T15:11:24.829261Z","iopub.status.idle":"2022-06-17T15:11:24.836167Z","shell.execute_reply.started":"2022-06-17T15:11:24.829223Z","shell.execute_reply":"2022-06-17T15:11:24.835044Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Aplicaremos este proceso para un solo tipo de resonancia magnética (aquí está el tipo T1w) para cada paciente. Por lo tanto, cada paciente tendrá 24 imágenes para el tratamiento.\n\n> # ANALIZAR","metadata":{}},{"cell_type":"code","source":"listMatrix = []\nfor i, patient in enumerate(tqdm(X_train)):\n    listVectors = []\n    sequence = load_dicom_images_3d(scan_id=str(patient),mri_type=MRI_TYPE)\n    for j in range(len(sequence)):\n        img = sequence[j]\n        img = np.expand_dims(img, axis=0)\n        img = tf.keras.applications.resnet50.preprocess_input(img)\n        img_vector = base_resnet.predict(img)\n        listVectors.append(np.array(img_vector))\n    \n    PatientMatrix = np.stack(listVectors)\n    listMatrix.append(PatientMatrix)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:11:24.84107Z","iopub.execute_input":"2022-06-17T15:11:24.841334Z","iopub.status.idle":"2022-06-17T15:44:25.968331Z","shell.execute_reply.started":"2022-06-17T15:11:24.84131Z","shell.execute_reply":"2022-06-17T15:44:25.967571Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Veamos ahora las formas de las matrices obtenidas tras la aplicación de este Learning Transfer:","metadata":{}},{"cell_type":"code","source":"print(f\"Number of patient matrix: {len(listMatrix)}\")\nprint(f\"Patient matrix shape: {listMatrix[0].shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:44:25.96978Z","iopub.execute_input":"2022-06-17T15:44:25.970354Z","iopub.status.idle":"2022-06-17T15:44:25.975876Z","shell.execute_reply.started":"2022-06-17T15:44:25.970314Z","shell.execute_reply":"2022-06-17T15:44:25.974992Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"![](https://aprendeconalf.es/docencia/python/manual/img/arrays.png)","metadata":{}},{"cell_type":"code","source":"#np.array(listMatrix, dtype=object).shape","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:44:25.97699Z","iopub.execute_input":"2022-06-17T15:44:25.977332Z","iopub.status.idle":"2022-06-17T15:44:31.898964Z","shell.execute_reply.started":"2022-06-17T15:44:25.977297Z","shell.execute_reply":"2022-06-17T15:44:31.898132Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"aplicar LSTM para la clasificacion\nLas redes neuronales recurrentes (RNN) son ampliamente utilizadas en inteligencia artificial cuando una noción temporal está involucrada en los datos.\n","metadata":{}},{"cell_type":"code","source":"model_input_dim = listMatrix[0].shape[2]","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:44:31.901462Z","iopub.execute_input":"2022-06-17T15:44:31.902153Z","iopub.status.idle":"2022-06-17T15:44:31.907491Z","shell.execute_reply.started":"2022-06-17T15:44:31.902111Z","shell.execute_reply":"2022-06-17T15:44:31.906704Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''Defino la arquitectura LSTM'''\ndef get_sequence_model():\n        model = keras.models.Sequential()\n    model.add(keras.layers.LSTM(100, input_shape=(NUM_IMAGES, model_input_dim), return_sequences=True))\n    model.add(keras.layers.Dropout(0.2))\n    model.add(keras.layers.Dense(100, activation='relu'))\n    model.add(keras.layers.Dense(1, activation='sigmoid'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:44:31.908573Z","iopub.execute_input":"2022-06-17T15:44:31.909144Z","iopub.status.idle":"2022-06-17T15:44:31.917324Z","shell.execute_reply.started":"2022-06-17T15:44:31.909107Z","shell.execute_reply":"2022-06-17T15:44:31.916637Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"![](https://upload.wikimedia.org/wikipedia/commons/f/f2/K-fold_cross_validation.jpg)\n\n# Explicacion K-FOLD  ↓","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ninputs = np.array(listMatrix)\ntargets = np.array(y_train).astype('float32').reshape((-1,1))\n\nnum_folds = 5\n\n# Definir la validación cruzada de K-fold\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# Evaluación del modelo K-fold Cross Validation\nhistory = {}\nfold_no = 1\nfor train_df, valid_df in kfold.split(inputs, targets):\n    \n    train_dataset = tf.data.Dataset.from_tensor_slices((inputs[train_df], targets[train_df]))\n    valid_dataset = tf.data.Dataset.from_tensor_slices((inputs[valid_df], targets[valid_df]))\n    \n    model = get_sequence_model()\n    model.compile(loss='binary_crossentropy', \n                  optimizer='adam', \n                  metrics='accuracy')\n    \n    # Define callbacks.\n    model_save = ModelCheckpoint(f'Brain_lstm_kfold_{fold_no}.h5', \n                                 save_best_only = True, \n                                 monitor = 'val_accuracy', \n                                 mode = 'max', verbose = 1)\n    early_stop = EarlyStopping(monitor = 'val_accuracy', \n                               patience = 25, mode = 'max', verbose = 1,\n                               restore_best_weights = True)\n    \n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n    \n    epochs = 200\n    history[fold_no] = model.fit(\n        train_dataset,\n        validation_data=valid_dataset, \n        epochs=epochs, \n        batch_size=32,\n        callbacks = [model_save, early_stop])\n    \n    # Aumentar el número de pliegues\n    fold_no += 1","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:44:31.919999Z","iopub.execute_input":"2022-06-17T15:44:31.92027Z","iopub.status.idle":"2022-06-17T15:49:52.970474Z","shell.execute_reply.started":"2022-06-17T15:44:31.920246Z","shell.execute_reply":"2022-06-17T15:49:52.969053Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ahora entrenaremos este modelo LSTM en las matrices compiladas para cada paciente utilizando Transfer Learning ResNet50.\n\nSe configura un EarlyStopping y se guardará el mejor modelo.\n\nAhora veamos los resultados de este entrenamiento:","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(20, 7))\nax = ax.ravel()\n\nfor fold in history:\n    for i, metric in enumerate([\"accuracy\",\"loss\"]):\n        ax[i].plot(history[fold].history[metric], label=\"train \"+str(fold))\n        ax[i].plot(history[fold].history[\"val_\" + metric], linestyle=\"dotted\", label=\"val \"+str(fold))\n        ax[i].set_title(\"Model {}\".format(metric))\n        ax[i].set_xlabel(\"epochs\")\n        ax[i].set_ylabel(metric)\n        ax[i].legend()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:49:52.97205Z","iopub.execute_input":"2022-06-17T15:49:52.972427Z","iopub.status.idle":"2022-06-17T15:49:53.437053Z","shell.execute_reply.started":"2022-06-17T15:49:52.972391Z","shell.execute_reply":"2022-06-17T15:49:53.435963Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kfold_results = pd.DataFrame(columns=[\"Fold\",\"Mean_Loss\",\"Mean_Accuracy\"])\nkey = []\nmean_loss = []\nmean_acc = []\nfor fold in history:\n    key.append(fold), \n    mean_loss.append(np.mean(history[fold].history[\"val_loss\"]))\n    mean_acc.append(np.mean(history[fold].history[\"val_accuracy\"]))\n\nkfold_results[\"Fold\"] = key\nkfold_results[\"Mean_Loss\"] = mean_loss\nkfold_results[\"Mean_Accuracy\"] = mean_acc\nkfold_results[\"Rank_Ratio\"] = (kfold_results[\"Mean_Loss\"] - kfold_results[\"Mean_Accuracy\"])\nkfold_results = kfold_results.sort_values(\"Rank_Ratio\", ascending=True)\nkfold_results","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:49:53.438281Z","iopub.execute_input":"2022-06-17T15:49:53.438841Z","iopub.status.idle":"2022-06-17T15:49:53.459078Z","shell.execute_reply.started":"2022-06-17T15:49:53.438804Z","shell.execute_reply":"2022-06-17T15:49:53.458311Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_kfold_model = './Brain_lstm_kfold_' + str(kfold_results.Fold.values[0]) + '.h5'\nprint(f\"The best select model is {best_kfold_model}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:49:53.460382Z","iopub.execute_input":"2022-06-17T15:49:53.461556Z","iopub.status.idle":"2022-06-17T15:49:53.470301Z","shell.execute_reply.started":"2022-06-17T15:49:53.461512Z","shell.execute_reply":"2022-06-17T15:49:53.469297Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"PREDICCIÓN EN EL CONJUNTO DE PRUEBA CON EL MEJOR MODELO\nAhora crearemos las matrices ResNet50 para el conjunto de prueba y haremos las predicciones en los pacientes de prueba.","metadata":{}},{"cell_type":"code","source":"X_test = test['BraTS21ID5'].values\ntest_listMatrix = []\nfor i, patient in enumerate(tqdm(X_test)):\n    test_listVectors = []\n    test_sequence = load_dicom_images_3d(scan_id=str(patient),mri_type=MRI_TYPE,split=\"test\")\n    for j in range(len(test_sequence)):\n        img = test_sequence[j]\n        img = np.expand_dims(img, axis=0)\n        img = tf.keras.applications.resnet50.preprocess_input(img)\n        img_vector = base_resnet.predict(img)\n        test_listVectors.append(np.array(img_vector))\n    \n    test_PatientMatrix = np.stack(test_listVectors)\n    test_listMatrix.append(test_PatientMatrix)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:49:53.471671Z","iopub.execute_input":"2022-06-17T15:49:53.472728Z","iopub.status.idle":"2022-06-17T15:55:00.894082Z","shell.execute_reply.started":"2022-06-17T15:49:53.472547Z","shell.execute_reply":"2022-06-17T15:55:00.890958Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of test patient matrix: {len(test_listMatrix)}\")\nprint(f\"Test patient matrix shape: {test_listMatrix[0].shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:55:00.895246Z","iopub.execute_input":"2022-06-17T15:55:00.896006Z","iopub.status.idle":"2022-06-17T15:55:00.902507Z","shell.execute_reply.started":"2022-06-17T15:55:00.89596Z","shell.execute_reply":"2022-06-17T15:55:00.901476Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = tf.data.Dataset.from_tensor_slices(test_listMatrix)\nlen(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:55:00.903898Z","iopub.execute_input":"2022-06-17T15:55:00.905089Z","iopub.status.idle":"2022-06-17T15:55:03.381369Z","shell.execute_reply.started":"2022-06-17T15:55:00.90505Z","shell.execute_reply":"2022-06-17T15:55:03.380595Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_model = keras.models.load_model(best_kfold_model)\npredict = final_model.predict(test_dataset)\nprint(predict.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:55:03.382538Z","iopub.execute_input":"2022-06-17T15:55:03.383007Z","iopub.status.idle":"2022-06-17T15:55:04.119861Z","shell.execute_reply.started":"2022-06-17T15:55:03.382968Z","shell.execute_reply":"2022-06-17T15:55:04.118955Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict = predict[:,0,0]\nfinal_predict = []\nfor i in range(len(test_listMatrix)):\n    i+=1\n    final_predict.append(round(predict[((i-1)*NUM_IMAGES):(NUM_IMAGES*i)].mean(),3))\nsubmission = test[[\"BraTS21ID\",\"MGMT_value\"]]\nsubmission[\"MGMT_value\"] = final_predict\nsubmission.to_csv('submission.csv',index=False)\nsubmission.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:55:04.121206Z","iopub.execute_input":"2022-06-17T15:55:04.121787Z","iopub.status.idle":"2022-06-17T15:55:04.143626Z","shell.execute_reply.started":"2022-06-17T15:55:04.121723Z","shell.execute_reply":"2022-06-17T15:55:04.14261Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nplt.hist(submission[\"MGMT_value\"])\nplt.title(\"Predicted probabilites distribution on test set\", \n          fontsize=18, color=\"#0b0a2d\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T15:55:04.145148Z","iopub.execute_input":"2022-06-17T15:55:04.145543Z","iopub.status.idle":"2022-06-17T15:55:04.330315Z","shell.execute_reply.started":"2022-06-17T15:55:04.145504Z","shell.execute_reply":"2022-06-17T15:55:04.329508Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Evaluacion**","metadata":{}}]}